---
title: "Master Script Run"
author: "Michael Schmidt"
date: "1/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Load Functions
```{r}
source("R/make_training_testing_data.R")
```


# Make Training Dataset

```{r}

start_time<-Sys.time()

training_data<-train_data_all(
  training_poly_path = "shapefiles/training_polygons12N_02122020_BS_UPDATE.shp", 
  tile_shape_path = "shapefiles/SanMiguel_West.shp", 
  height_imagery_folder = "DATA/SanMiguel_West_heights_added"
)

start_time-Sys.time()

saveRDS(training_data, "DATA/training_data/training_polygons12N_02122020_BS_UPDATE2.rds")

```

## Make Training Datasets with New Method
This took over a day. Need to parallelize this bad!
```{r}
source("R/load_funcs.R")
library(doParallel)
start_time<-Sys.time()

n_cores<-24
cl <- makeCluster(n_cores)
registerDoParallel(cl)

train_data_all_add_height<-train_data_all_add_heights(
  training_poly_path = "shapefiles/training_polygons12N_03172020_UPDATE_OTHER_VEG.shp", 
  tile_shape_path = "shapefiles/SanMiguel_West.shp", 
  imagery_folder = "DATA/Tiffs_W_SM",
  height_raster_folder = "DATA/NOC_heights/WestSM_dZgridded",
  parallel = n_cores,
  scale = TRUE
)
stopCluster(cl)

start_time-Sys.time()

# new_test_data<-train_data_all_add_height%>%
#   purrr::set_names(c("band1", "band2", "band3", "band4", "height", "Class", "Id"))

saveRDS(train_data_all_add_height, "DATA/training_data/training_polygons12N_03172020_UPDATE_OTHER_VEG_normalized_scale.rds")
```

## Run Random Forest
```{r}
library(CAST)
library(doParallel)
library(caret)
library(tidyverse)
set.seed(1234)
options(scipen=999)
data<-readRDS("DATA/training_data/training_polygons12N_03172020_UPDATE_OTHER_VEG_normalized_scale.rds")%>%
  drop_na()%>%
  mutate(Class = case_when(
    Class %in% c(7,2) ~ "Sage", #Sage and Black Sage 
    Class %in% c(4,5) ~ "Other_veg", #Other_veg and other_shrub,
    Class == 6 ~ "PJ", # PJ
    Class == 1 ~ "BG_rock", # BG_rock
    Class == 3 ~ "Grass" #Grass
  ),
  height = round(height, digits = 2))

trainIndex<-createDataPartition(data$Class, p = .8, list = FALSE, times = 1)

data_train<-data[trainIndex, ]
data_test<-data[-trainIndex, ]

indeces<-CreateSpacetimeFolds(data_train, spacevar = "Id", k = 15)

##indeces$index



control <- trainControl(method = "cv",
                        number = 15,
                        sampling="down",
                        index = indeces$index
                     )

mtry<-c(2:4)
tunegrid <-expand.grid(.mtry = mtry)

no_cores<-4
cl<-makePSOCKcluster(no_cores)
registerDoParallel(cl)

start_time<-Sys.time()
caret_fit_base<-train(as.factor(Class) ~ . , 
                  data=select(data_train, -Id),
                  method="rf",
                  trControl=control,
                  tuneGrid=tunegrid,
                  metric= "Accuracy",
                  ntree = 1500
                  )
end_time<-Sys.time()

start_time-end_time

stopCluster(cl)

caret_fit_base

prediction<-bind_cols(data_test, predict = predict(caret_fit_base, data_test))

prop.table(caret::confusionMatrix(as.factor(prediction$Class), prediction$predict)$table, 2)

varImp(caret_fit_base, scale = FALSE)

saveRDS(caret_fit_base, "model_runs/OTHER_VEG_NORM_scale/training_polygons12N_03172020_UPDATE_OTHER_VEG_normalized_scale.rds")


```

## Make prediction with model
```{r}
source("R/load_funcs.R")
tiles<-list.files("DATA/Tiffs_W_SM", pattern = ".tif", full.names = T)%>%
  sample(10)

tiles2<-tiles[3:8]

always_runs<-c("DATA/Tiffs_W_SM/SM_GypsumGapNW_0102_180611.tif", "DATA/Tiffs_W_SM/SM_GypsumGapNW_0103_180611.tif" , "DATA/Tiffs_W_SM/SM_GypsumGapNW_0104_180611.tif")

tiles<-append(tiles, always_runs)

start_time<-Sys.time()
predict_raster(tiles, 
               "model_runs/OTHER_VEG_NORM_scale/training_polygons12N_03172020_UPDATE_OTHER_VEG_normalized_scale.rds", 
               "DATA/NOC_heights/WestSM_dZgridded")
Sys.time()-start_time
```

