---
title: "Master Script Run"
author: "Michael Schmidt"
date: "1/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Load Functions
```{r}
source("R/make_training_testing_data.R")
```


# Make Training Dataset

```{r}

start_time<-Sys.time()

training_data<-train_data_all(
  training_poly_path = "training_polygons12N_03172020_UPDATE_OTHER_VEG.shp", 
  tile_shape_path = "shapefiles/SanMiguel_West.shp", 
  height_imagery_folder = "DATA/SanMiguel_West_heights_added"
)

start_time-Sys.time()

saveRDS(training_data, "DATA/training_data/training_polygons12N_02122020_BS_UPDATE2.rds")

```

## Make Training Datasets with New Method
This took over a day. Need to parallelize this bad!
```{r}
source("R/load_funcs.R")
library(doParallel)

rm(height_path, imagery_path, r, s,predict, model)
gc()
rasterOptions(
  maxmemory = 5e+10,
  chunksize = 1e+09
)

n_cores<-20
cl<-makePSOCKcluster(n_cores) ##if you're on a mac, this should be makeCluster()

registerDoParallel(cl)

start_time<-Sys.time()
train_data_all_add_height<-train_data_all_add_heights(
  training_poly_path = "shapefiles/training_polygons12N_09152020_ADD_SHADOW.shp", 
  tile_shape_path = "shapefiles/SanMiguel_West.shp", 
  imagery_folder = "DATA/SanMiguel_West/Tiffs",
  height_raster_folder = "DATA/NOC_heights/WestSM_dZgridded"
)
start_time-Sys.time()

final_data<-do.call(rbind, train_data_all_add_height)%>%
  as_tibble()

final_data<-do.call(rbind, data)%>%
  as_tibble()

stopCluster(cl)

# new_test_data<-train_data_all_add_height%>%
#   purrr::set_names(c("band1", "band2", "band3", "band4", "height", "Class", "Id"))

saveRDS(final_data, "DATA/training_data/training_polygons12N_09152020_ADD_SHADOW.rds")
```



## Run Random Forest
```{r}
library(CAST)
library(doParallel)
library(caret)
library(tidyverse)
gc()
set.seed(1234)
options(scipen=999)

data<-readRDS("DATA/training_data/training_polygons12N_09152020_ADD_SHADOW.rds")%>%
  drop_na()%>%
  mutate(Class = case_when(
    Class %in% c(7,2) ~ "Sage", #Sage and Black Sage 
    Class %in% c(4,5) ~ "Other_veg", #Other_veg and other_shrub,
    Class == 6 ~ "PJ", # PJ
    Class == 1 ~ "BG_rock", # BG_rock
    Class == 3 ~ "Grass", #Grass
    Class == 8 ~ "Shadow"
  ),
  height = round(height, digits = 2))


trainIndex<-createDataPartition(data$Class, p = .8, list = FALSE, times = 1)

data_train<-data[trainIndex, ]
data_test<-data[-trainIndex, ]

indeces<-CreateSpacetimeFolds(data_train, spacevar = "Id", k = 20)

##indeces$index



control <- trainControl(method = "cv",
                        number = 20,
                        sampling="down",
                        index = indeces$index
                     )

mtry<-c(2:4)
tunegrid <-expand.grid(.mtry = mtry)

no_cores<-4
cl<-makePSOCKcluster(no_cores)
registerDoParallel(cl)

start_time<-Sys.time()
caret_fit_base<-train(as.factor(Class) ~ . , 
                  data=select(data_train, -Id),
                  method="rf",
                  trControl=control,
                  tuneGrid=tunegrid,
                  metric= "Accuracy",
                  ntree = 1500
                  )
end_time<-Sys.time()

start_time-end_time

stopCluster(cl)

##caret_fit_base<-readRDS("model_runs/UPDATE_OTHER_VEG_normalized_scale_more_data_03282020_new/training_polygons12N_03172020_UPDATE_OTHER_VEG_normalized_scale_more_data_03282020_new.rds")

caret_fit_base

prediction<-bind_cols(data_test, predict = predict(caret_fit_base, data_test))

prop.table(caret::confusionMatrix(as.factor(prediction$Class), prediction$predict)$table, 2)

varImp(caret_fit_base, scale = FALSE)

saveRDS(caret_fit_base, "model_runs/training_polygons12N_09152020_ADD_SHADOW/training_polygons12N_09152020_ADD_SHADOW.rds")


```

## Make prediction with model
```{r}
source("R/load_funcs.R")
library(here)
library(snow)
gc()
rasterOptions(
  maxmemory = 5e+10,
  chunksize = 1e+09
)
tiles<-list.files("DATA/Tiffs_W_SM", pattern = ".tif$", full.names = T)


# tiles<-tiles[-2]
# 
# 
# always_runs<-c("DATA/Tiffs_W_SM/SM_GypsumGapNW_0102_180611.tif", "DATA/Tiffs_W_SM/SM_GypsumGapNW_0103_180611.tif" , "DATA/Tiffs_W_SM/SM_GypsumGapNW_0104_180611.tif")
# 
# tiles<-append(tiles, always_runs)
# 
# tiles2<-tiles[3:13]

start_time<-Sys.time()
predict_raster(tiles, 
               "model_runs/add_shadow_no_normalize_MSAVI/training_polygons12N_09152020_ADD_SHADOW.rds", 
               "DATA/NOC_heights/WestSM_dZgridded")
Sys.time()-start_time
```

## Parallel predict
```{r}
library(parallel)
library(here)
source("R/load_funcs.R")


tiles<-tibble(
  tile_path=list.files("DATA/Tiffs_W_SM", pattern = ".tif$", full.names = T),
  tile_name=list.files("DATA/Tiffs_W_SM", pattern = ".tif$")
)

##tiles<-list.files("DATA/Tiffs_W_SM", pattern = ".tif$", full.names = T)

complete_tiles<-tibble(tile_name=list.files("model_runs/add_shadow_no_normalize_MSAVI", pattern = ".tif$"))%>%
  mutate(tile_name=str_extract(tile_name, "(?<=TILE_).*$"))

tiles<-tiles%>%
  anti_join(complete_tiles)%>%
  pull(tile_path)

shadow_model<-readRDS("model_runs/add_shadow_no_normalize_MSAVI_V2/training_polygons12N_09152020_ADD_SHADOW.rds")

cl<-makeCluster(15)
clusterExport(cl, varlist=c("shadow_model", "lfn_2", "height_merge2"), envir=environment())
clusterEvalQ(cl, 
             list(library(tidyverse), 
                  library(raster), 
                  library(RStoolbox), 
                  library(here),
                  rasterOptions(
                    tmpdir = here("temp_rasters"),
                    maxmemory = 5e+10,
                    chunksize = 1e+09
                  )
             )
)


start_time<-Sys.time()
parLapply(cl, tiles, predict_raster2, 
          model = shadow_model, 
          height_raster_folder="DATA/NOC_heights/WestSM_dZgridded" ,
          model_name="shadow_model_and_MSAVI_V2", 
          output_folder="model_runs/add_shadow_no_normalize_MSAVI_V2")

Sys.time()-start_time

stopCluster(cl)
```

tile_path, model, height_raster_folder, model_name, output_folder = NULL
